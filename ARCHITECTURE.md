# å¤§æ–‡ä»¶ä¸Šä¼  - å¤§ä¸­å‹é¡¹ç›®å®ç°æ–¹æ¡ˆ

## ğŸ“Š ç›®å½•

1. [å½“å‰å®ç° vs å¤§ä¸­å‹é¡¹ç›®å¯¹æ¯”](#å½“å‰å®ç°-vs-å¤§ä¸­å‹é¡¹ç›®å¯¹æ¯”)
2. [å¤§ä¸­å‹é¡¹ç›®æ¶æ„è®¾è®¡](#å¤§ä¸­å‹é¡¹ç›®æ¶æ„è®¾è®¡)
3. [æ ¸å¿ƒæŠ€æœ¯æ ˆ](#æ ¸å¿ƒæŠ€æœ¯æ ˆ)
4. [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
5. [å®‰å…¨æ€§è€ƒè™‘](#å®‰å…¨æ€§è€ƒè™‘)
6. [ç›‘æ§ä¸æ—¥å¿—](#ç›‘æ§ä¸æ—¥å¿—)
7. [éƒ¨ç½²æ–¹æ¡ˆ](#éƒ¨ç½²æ–¹æ¡ˆ)

---

## å½“å‰å®ç° vs å¤§ä¸­å‹é¡¹ç›®å¯¹æ¯”

### å½“å‰å®ç°ï¼ˆå°å‹é¡¹ç›®ï¼‰

```
UploadFiles/
â”œâ”€â”€ server/
â”‚   â””â”€â”€ index.js          # æ‰€æœ‰åç«¯é€»è¾‘ï¼ˆ361è¡Œï¼‰
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ views/
â”‚   â”‚   â””â”€â”€ FileUpload.vue    # æ‰€æœ‰å‰ç«¯é€»è¾‘ï¼ˆ508è¡Œï¼‰
â”‚   â””â”€â”€ workers/
â”‚       â””â”€â”€ fileSliceWorker.js  # æ–‡ä»¶åˆ‡ç‰‡Worker
â””â”€â”€ package.json
```

**ç‰¹ç‚¹ï¼š**
- âœ… ä»£ç é›†ä¸­ï¼Œæ˜“äºç†è§£
- âœ… å¿«é€Ÿå¼€å‘ï¼Œé€‚åˆåŸå‹
- âš ï¸ å•æ–‡ä»¶è¿‡å¤§ï¼Œç»´æŠ¤å›°éš¾
- âš ï¸ ç¼ºå°‘é”™è¯¯ç›‘æ§å’Œæ—¥å¿—
- âš ï¸ æ²¡æœ‰ç”¨æˆ·è®¤è¯å’Œæƒé™æ§åˆ¶

---

## å¤§ä¸­å‹é¡¹ç›®æ¶æ„è®¾è®¡

### æ¨èç›®å½•ç»“æ„

```
large-file-upload/
â”œâ”€â”€ client/                          # å‰ç«¯é¡¹ç›®
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ FileUpload.vue          # ä¸»ä¸Šä¼ ç»„ä»¶
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ UploadQueue.vue         # ä¸Šä¼ é˜Ÿåˆ—ç®¡ç†
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ProgressBar.vue         # è¿›åº¦æ¡ç»„ä»¶
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChunkUploader.vue       # åˆ†ç‰‡ä¸Šä¼ å™¨
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ UploadHistory.vue       # ä¸Šä¼ å†å²
â”‚   â”‚   â”‚   â””â”€â”€ common/
â”‚   â”‚   â”‚       â”œâ”€â”€ ErrorBoundary.vue       # é”™è¯¯è¾¹ç•Œ
â”‚   â”‚   â”‚       â””â”€â”€ LoadingSpinner.vue      # åŠ è½½åŠ¨ç”»
â”‚   â”‚   â”œâ”€â”€ composables/
â”‚   â”‚   â”‚   â”œâ”€â”€ useFileUpload.js            # ä¸Šä¼ é€»è¾‘Hook
â”‚   â”‚   â”‚   â”œâ”€â”€ useChunkManager.js          # åˆ†ç‰‡ç®¡ç†Hook
â”‚   â”‚   â”‚   â”œâ”€â”€ useUploadQueue.js           # é˜Ÿåˆ—ç®¡ç†Hook
â”‚   â”‚   â”‚   â””â”€â”€ useWebSocket.js             # WebSocketè¿æ¥Hook
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ uploadService.js            # ä¸Šä¼ APIæœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ authService.js              # è®¤è¯æœåŠ¡
â”‚   â”‚   â”‚   â””â”€â”€ websocketService.js         # WebSocketæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”‚   â”œâ”€â”€ uploadStore.js              # ä¸Šä¼ çŠ¶æ€ç®¡ç†
â”‚   â”‚   â”‚   â””â”€â”€ userStore.js                # ç”¨æˆ·çŠ¶æ€ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ hashUtils.js                # å“ˆå¸Œè®¡ç®—å·¥å…·
â”‚   â”‚   â”‚   â”œâ”€â”€ fileUtils.js                # æ–‡ä»¶å¤„ç†å·¥å…·
â”‚   â”‚   â”‚   â””â”€â”€ storageUtils.js             # å­˜å‚¨å·¥å…·
â”‚   â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”‚   â”œâ”€â”€ fileSliceWorker.js          # æ–‡ä»¶åˆ‡ç‰‡Worker
â”‚   â”‚   â”‚   â”œâ”€â”€ hashWorker.js               # å“ˆå¸Œè®¡ç®—Worker
â”‚   â”‚   â”‚   â””â”€â”€ uploadWorker.js             # ä¸Šä¼ Workeræ± 
â”‚   â”‚   â””â”€â”€ main.js
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â””â”€â”€ sw.js                           # Service Worker
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ server/                          # åç«¯é¡¹ç›®
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â”œâ”€â”€ uploadController.js         # ä¸Šä¼ æ§åˆ¶å™¨
â”‚   â”‚   â”‚   â”œâ”€â”€ authController.js           # è®¤è¯æ§åˆ¶å™¨
â”‚   â”‚   â”‚   â””â”€â”€ fileController.js           # æ–‡ä»¶ç®¡ç†æ§åˆ¶å™¨
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ uploadService.js            # ä¸Šä¼ ä¸šåŠ¡é€»è¾‘
â”‚   â”‚   â”‚   â”œâ”€â”€ chunkService.js             # åˆ†ç‰‡å¤„ç†æœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ mergeService.js             # åˆå¹¶æœåŠ¡
â”‚   â”‚   â”‚   â”œâ”€â”€ storageService.js           # å­˜å‚¨æœåŠ¡ï¼ˆOSS/S3ï¼‰
â”‚   â”‚   â”‚   â””â”€â”€ cacheService.js            # ç¼“å­˜æœåŠ¡ï¼ˆRedisï¼‰
â”‚   â”‚   â”œâ”€â”€ middleware/
â”‚   â”‚   â”‚   â”œâ”€â”€ authMiddleware.js           # è®¤è¯ä¸­é—´ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ rateLimitMiddleware.js      # é™æµä¸­é—´ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ uploadMiddleware.js        # ä¸Šä¼ ä¸­é—´ä»¶
â”‚   â”‚   â”‚   â””â”€â”€ errorMiddleware.js          # é”™è¯¯å¤„ç†ä¸­é—´ä»¶
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ uploadRoutes.js             # ä¸Šä¼ è·¯ç”±
â”‚   â”‚   â”‚   â”œâ”€â”€ authRoutes.js               # è®¤è¯è·¯ç”±
â”‚   â”‚   â”‚   â””â”€â”€ fileRoutes.js               # æ–‡ä»¶è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ File.js                     # æ–‡ä»¶æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ User.js                     # ç”¨æˆ·æ¨¡å‹
â”‚   â”‚   â”‚   â””â”€â”€ UploadRecord.js             # ä¸Šä¼ è®°å½•æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ hashUtils.js                # å“ˆå¸Œå·¥å…·
â”‚   â”‚   â”‚   â”œâ”€â”€ fileUtils.js                # æ–‡ä»¶å·¥å…·
â”‚   â”‚   â”‚   â””â”€â”€ logger.js                   # æ—¥å¿—å·¥å…·
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ index.js                    # é…ç½®æ–‡ä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ uploadConfig.js             # ä¸Šä¼ é…ç½®
â”‚   â”‚   â”‚   â””â”€â”€ storageConfig.js            # å­˜å‚¨é…ç½®
â”‚   â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â”‚   â”œâ”€â”€ cleanupJob.js               # æ¸…ç†ä»»åŠ¡
â”‚   â”‚   â”‚   â””â”€â”€ mergeJob.js                 # åˆå¹¶ä»»åŠ¡
â”‚   â”‚   â””â”€â”€ app.js
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â””â”€â”€ e2e/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ shared/                          # å…±äº«ä»£ç 
â”‚   â”œâ”€â”€ constants/
â”‚   â”‚   â”œâ”€â”€ uploadConstants.js            # ä¸Šä¼ å¸¸é‡
â”‚   â”‚   â””â”€â”€ errorCodes.js                  # é”™è¯¯ç 
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ uploadTypes.js                # TypeScriptç±»å‹å®šä¹‰
â”‚
â””â”€â”€ docker-compose.yml               # Dockerç¼–æ’
```

---

## æ ¸å¿ƒæŠ€æœ¯æ ˆ

### å‰ç«¯æŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç”¨é€” | æ¨èç‰ˆæœ¬ |
|------|------|----------|
| **Vue 3** | å‰ç«¯æ¡†æ¶ | ^3.3.0 |
| **TypeScript** | ç±»å‹å®‰å…¨ | ^5.0.0 |
| **Pinia** | çŠ¶æ€ç®¡ç† | ^2.1.0 |
| **Vue Router** | è·¯ç”±ç®¡ç† | ^4.2.0 |
| **Vite** | æ„å»ºå·¥å…· | ^5.0.0 |
| **SparkMD5** | æ–‡ä»¶å“ˆå¸Œè®¡ç®— | ^3.0.2 |
| **Axios** | HTTPå®¢æˆ·ç«¯ | ^1.6.0 |
| **Socket.io-client** | WebSocketå®¢æˆ·ç«¯ | ^4.6.0 |
| **Workbox** | Service Workerå·¥å…· | ^7.0.0 |

### åç«¯æŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç”¨é€” | æ¨èç‰ˆæœ¬ |
|------|------|----------|
| **Node.js** | è¿è¡Œæ—¶ | ^20.0.0 |
| **Express** | Webæ¡†æ¶ | ^4.18.0 |
| **TypeScript** | ç±»å‹å®‰å…¨ | ^5.0.0 |
| **MongoDB** | ä¸»æ•°æ®åº“ | ^7.0.0 |
| **Redis** | ç¼“å­˜/é˜Ÿåˆ— | ^7.0.0 |
| **Bull** | ä»»åŠ¡é˜Ÿåˆ— | ^4.12.0 |
| **Socket.io** | WebSocketæœåŠ¡ | ^4.6.0 |
| **AWS S3 / é˜¿é‡Œäº‘OSS** | å¯¹è±¡å­˜å‚¨ | - |
| **Multer** | æ–‡ä»¶ä¸Šä¼ ä¸­é—´ä»¶ | ^1.4.5 |
| **Winston** | æ—¥å¿—ç®¡ç† | ^3.11.0 |
| **Prometheus** | ç›‘æ§æŒ‡æ ‡ | - |

---

## æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. å‰ç«¯ä¼˜åŒ–

#### 1.1 Web Worker æ± åŒ–

```javascript
// workers/uploadWorkerPool.js
class UploadWorkerPool {
  constructor(maxWorkers = 4) {
    this.workers = []
    this.queue = []
    this.maxWorkers = maxWorkers
  }

  // åˆå§‹åŒ–Workeræ± 
  init() {
    for (let i = 0; i < this.maxWorkers; i++) {
      const worker = new Worker('./uploadWorker.js')
      this.workers.push({
        worker,
        busy: false
      })
    }
  }

  // è·å–ç©ºé—²Worker
  getWorker() {
    return this.workers.find(w => !w.busy)
  }

  // æ‰§è¡Œä»»åŠ¡
  async execute(task) {
    const workerObj = this.getWorker()
    
    if (!workerObj) {
      // ç­‰å¾…ç©ºé—²Worker
      return new Promise(resolve => {
        this.queue.push({ task, resolve })
      })
    }

    workerObj.busy = true
    const result = await this.runTask(workerObj.worker, task)
    workerObj.busy = false
    
    // å¤„ç†é˜Ÿåˆ—
    if (this.queue.length > 0) {
      const next = this.queue.shift()
      this.execute(next.task).then(next.resolve)
    }
    
    return result
  }

  runTask(worker, task) {
    return new Promise((resolve, reject) => {
      worker.onmessage = (e) => {
        if (e.data.type === 'TASK_COMPLETE') {
          resolve(e.data.result)
        }
      }
      worker.onerror = reject
      worker.postMessage(task)
    })
  }
}
```

#### 1.2 åˆ†ç‰‡ä¸Šä¼ ä¼˜åŒ–

```javascript
// composables/useChunkManager.js
import { ref } from 'vue'

export function useChunkManager() {
  const CHUNK_SIZE = 5 * 1024 * 1024 // 5MB
  const MAX_RETRIES = 3
  const RETRY_DELAY = 1000

  // æ™ºèƒ½åˆ†ç‰‡å¤§å°è°ƒæ•´
  const calculateOptimalChunkSize = (fileSize, networkSpeed) => {
    // æ ¹æ®æ–‡ä»¶å¤§å°å’Œç½‘ç»œé€Ÿåº¦åŠ¨æ€è°ƒæ•´
    if (fileSize < 100 * 1024 * 1024) {
      return 2 * 1024 * 1024 // å°æ–‡ä»¶ï¼š2MB
    } else if (fileSize < 1024 * 1024 * 1024) {
      return 5 * 1024 * 1024 // ä¸­æ–‡ä»¶ï¼š5MB
    } else {
      return 10 * 1024 * 1024 // å¤§æ–‡ä»¶ï¼š10MB
    }
  }

  // å¸¦é‡è¯•çš„ä¸Šä¼ 
  const uploadWithRetry = async (chunk, retries = MAX_RETRIES) => {
    for (let i = 0; i < retries; i++) {
      try {
        return await uploadChunk(chunk)
      } catch (error) {
        if (i === retries - 1) throw error
        await new Promise(resolve => setTimeout(resolve, RETRY_DELAY * (i + 1)))
      }
    }
  }

  // å¹¶å‘æ§åˆ¶
  const uploadChunksInParallel = async (chunks, maxConcurrency = 3) => {
    const results = []
    const executing = []

    for (const chunk of chunks) {
      const promise = uploadWithRetry(chunk).then(result => {
        executing.splice(executing.indexOf(promise), 1)
        return result
      })

      results.push(promise)
      executing.push(promise)

      if (executing.length >= maxConcurrency) {
        await Promise.race(executing)
      }
    }

    return Promise.all(results)
  }

  return {
    calculateOptimalChunkSize,
    uploadWithRetry,
    uploadChunksInParallel
  }
}
```

#### 1.3 å“ˆå¸Œè®¡ç®—ä¼˜åŒ–

```javascript
// utils/hashUtils.js
import SparkMD5 from 'spark-md5'

export class HashCalculator {
  constructor() {
    this.worker = null
  }

  // ä½¿ç”¨Workerè®¡ç®—æ–‡ä»¶å“ˆå¸Œ
  async calculateFileHash(file, chunkSize = 2 * 1024 * 1024) {
    return new Promise((resolve, reject) => {
      const spark = new SparkMD5.ArrayBuffer()
      const reader = new FileReader()
      const chunks = Math.ceil(file.size / chunkSize)
      let currentChunk = 0

      reader.onload = (e) => {
        spark.append(e.target.result)
        currentChunk++

        if (currentChunk < chunks) {
          loadNext()
        } else {
          const hash = spark.end()
          resolve(hash)
        }
      }

      reader.onerror = reject

      const loadNext = () => {
        const start = currentChunk * chunkSize
        const end = Math.min(start + chunkSize, file.size)
        reader.readAsArrayBuffer(file.slice(start, end))
      }

      loadNext()
    })
  }

  // å¢é‡å“ˆå¸Œè®¡ç®—ï¼ˆç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
  async calculateChunkHash(chunk) {
    return new Promise((resolve, reject) => {
      const spark = new SparkMD5.ArrayBuffer()
      const reader = new FileReader()

      reader.onload = (e) => {
        spark.append(e.target.result)
        resolve(spark.end())
      }

      reader.onerror = reject
      reader.readAsArrayBuffer(chunk)
    })
  }
}
```

### 2. åç«¯ä¼˜åŒ–

#### 2.1 ä½¿ç”¨ Redis ç¼“å­˜ä¸Šä¼ çŠ¶æ€

```javascript
// services/cacheService.js
import Redis from 'ioredis'

class CacheService {
  constructor() {
    this.redis = new Redis({
      host: process.env.REDIS_HOST,
      port: process.env.REDIS_PORT,
      password: process.env.REDIS_PASSWORD
    })
  }

  // ä¿å­˜ä¸Šä¼ è¿›åº¦
  async saveUploadProgress(fileHash, data) {
    const key = `upload:${fileHash}`
    await this.redis.setex(key, 3600, JSON.stringify(data)) // 1å°æ—¶è¿‡æœŸ
  }

  // è·å–ä¸Šä¼ è¿›åº¦
  async getUploadProgress(fileHash) {
    const key = `upload:${fileHash}`
    const data = await this.redis.get(key)
    return data ? JSON.parse(data) : null
  }

  // æ›´æ–°å·²ä¸Šä¼ åˆ†ç‰‡
  async addUploadedChunk(fileHash, chunkIndex) {
    const key = `upload:${fileHash}:chunks`
    await this.redis.sadd(key, chunkIndex)
    await this.redis.expire(key, 3600)
  }

  // è·å–å·²ä¸Šä¼ åˆ†ç‰‡
  async getUploadedChunks(fileHash) {
    const key = `upload:${fileHash}:chunks`
    const chunks = await this.redis.smembers(key)
    return chunks.map(Number)
  }

  // åˆ é™¤ä¸Šä¼ è®°å½•
  async deleteUploadRecord(fileHash) {
    await this.redis.del(`upload:${fileHash}`)
    await this.redis.del(`upload:${fileHash}:chunks`)
  }
}

export default new CacheService()
```

#### 2.2 ä½¿ç”¨ Bull ä»»åŠ¡é˜Ÿåˆ—å¤„ç†åˆå¹¶

```javascript
// jobs/mergeJob.js
import Queue from 'bull'
import path from 'path'
import fs from 'fs-extra'
import cacheService from '../services/cacheService.js'

const mergeQueue = new Queue('file-merge', {
  redis: {
    host: process.env.REDIS_HOST,
    port: process.env.REDIS_PORT
  }
})

// å¤„ç†åˆå¹¶ä»»åŠ¡
mergeQueue.process(async (job) => {
  const { fileHash, fileName, totalChunks } = job.data

  const uploadDir = path.join(process.env.UPLOAD_DIR, fileHash)
  const tempChunkDir = path.join(uploadDir, 'temp_chunks')
  const filePath = path.join(uploadDir, fileName)

  // æŒ‰é¡ºåºåˆå¹¶åˆ†ç‰‡
  const writeStream = fs.createWriteStream(filePath)

  for (let i = 0; i < totalChunks; i++) {
    const chunkPath = path.join(tempChunkDir, `${i}`)
    const chunkData = await fs.readFile(chunkPath)
    writeStream.write(chunkData)
    await fs.remove(chunkPath)
  }

  writeStream.end()

  // æ¸…ç†ä¸´æ—¶ç›®å½•å’Œç¼“å­˜
  await fs.remove(tempChunkDir)
  await cacheService.deleteUploadRecord(fileHash)

  return { success: true, filePath }
})

// æ·»åŠ åˆå¹¶ä»»åŠ¡
export const addMergeJob = (data) => {
  return mergeQueue.add(data, {
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000
    }
  })
}

export default mergeQueue
```

#### 2.3 ä½¿ç”¨å¯¹è±¡å­˜å‚¨ï¼ˆS3/OSSï¼‰

```javascript
// services/storageService.js
import AWS from 'aws-sdk'
import fs from 'fs-extra'

class StorageService {
  constructor() {
    this.s3 = new AWS.S3({
      accessKeyId: process.env.AWS_ACCESS_KEY_ID,
      secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
      region: process.env.AWS_REGION
    })
  }

  // ä¸Šä¼ åˆ†ç‰‡åˆ°S3
  async uploadChunk(fileHash, chunkIndex, chunkData) {
    const key = `uploads/${fileHash}/chunks/${chunkIndex}`
    
    await this.s3.upload({
      Bucket: process.env.AWS_BUCKET,
      Key: key,
      Body: chunkData
    }).promise()
  }

  // åˆå¹¶S3åˆ†ç‰‡
  async mergeChunks(fileHash, fileName, totalChunks) {
    const parts = []
    
    for (let i = 0; i < totalChunks; i++) {
      const key = `uploads/${fileHash}/chunks/${i}`
      const head = await this.s3.headObject({
        Bucket: process.env.AWS_BUCKET,
        Key: key
      }).promise())
      
      parts.push({
        PartNumber: i + 1,
        ETag: head.ETag
      })
    }

    // åˆ›å»ºåˆå¹¶åçš„æ–‡ä»¶
    const result = await this.s3.completeMultipartUpload({
      Bucket: process.env.AWS_BUCKET,
      Key: `uploads/${fileHash}/${fileName}`,
      UploadId: uploadId,
      MultipartUpload: {
        Parts: parts
      }
    }).promise()

    // æ¸…ç†åˆ†ç‰‡
    for (let i = 0; i < totalChunks; i++) {
      await this.s3.deleteObject({
        Bucket: process.env.AWS_BUCKET,
        Key: `uploads/${fileHash}/chunks/${i}`
      }).promise()
    }

    return result.Location
  }
}

export default new StorageService()
```

---

## å®‰å…¨æ€§è€ƒè™‘

### 1. æ–‡ä»¶ç±»å‹éªŒè¯

```javascript
// middleware/uploadMiddleware.js
const ALLOWED_MIME_TYPES = [
  'image/jpeg',
  'image/png',
  'image/gif',
  'application/pdf',
  'application/zip',
  'video/mp4',
  'video/quicktime'
]

const MAX_FILE_SIZE = 10 * 1024 * 1024 * 1024 // 10GB

export const validateFile = (req, res, next) => {
  const { file } = req

  if (!file) {
    return res.status(400).json({ error: 'æ²¡æœ‰æ–‡ä»¶' })
  }

  // æ£€æŸ¥æ–‡ä»¶å¤§å°
  if (file.size > MAX_FILE_SIZE) {
    return res.status(400).json({ error: 'æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶' })
  }

  // æ£€æŸ¥æ–‡ä»¶ç±»å‹
  if (!ALLOWED_MIME_TYPES.includes(file.mimetype)) {
    return res.status(400).json({ error: 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹' })
  }

  // æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
  const ext = path.extname(file.originalname).toLowerCase()
  const ALLOWED_EXTS = ['.jpg', '.jpeg', '.png', '.gif', '.pdf', '.zip', '.mp4', '.mov']
  
  if (!ALLOWED_EXTS.includes(ext)) {
    return res.status(400).json({ error: 'ä¸æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å' })
  }

  next()
}
```

### 2. ç—…æ¯’æ‰«æ

```javascript
// services/scanService.js
import { exec } from 'child_process'
import { promisify } from 'util'

const execAsync = promisify(exec)

export const scanFile = async (filePath) => {
  try {
    // ä½¿ç”¨ClamAVæ‰«ææ–‡ä»¶
    const { stdout } = await execAsync(`clamscan ${filePath}`)
    
    if (stdout.includes('FOUND')) {
      throw new Error('æ–‡ä»¶åŒ…å«ç—…æ¯’')
    }
    
    return { clean: true }
  } catch (error) {
    throw new Error('ç—…æ¯’æ‰«æå¤±è´¥')
  }
}
```

### 3. è®¿é—®æ§åˆ¶

```javascript
// middleware/authMiddleware.js
import jwt from 'jsonwebtoken'

export const authenticate = (req, res, next) => {
  const token = req.headers.authorization?.split(' ')[1]

  if (!token) {
    return res.status(401).json({ error: 'æœªæˆæƒ' })
  }

  try {
    const decoded = jwt.verify(token, process.env.JWT_SECRET)
    req.user = decoded
    next()
  } catch (error) {
    return res.status(401).json({ error: 'æ— æ•ˆçš„ä»¤ç‰Œ' })
  }
}

export const authorize = (roles) => {
  return (req, res, next) => {
    if (!roles.includes(req.user.role)) {
      return res.status(403).json({ error: 'æƒé™ä¸è¶³' })
    }
    next()
  }
}
```

---

## ç›‘æ§ä¸æ—¥å¿—

### 1. æ—¥å¿—ç®¡ç†

```javascript
// utils/logger.js
import winston from 'winston'

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/combined.log' })
  ]
})

if (process.env.NODE_ENV !== 'production') {
  logger.add(new winston.transports.Console({
    format: winston.format.simple()
  }))
}

export default logger
```

### 2. ç›‘æ§æŒ‡æ ‡

```javascript
// utils/metrics.js
import client from 'prom-client'

// ä¸Šä¼ æŒ‡æ ‡
export const uploadDuration = new client.Histogram({
  name: 'upload_duration_seconds',
  help: 'ä¸Šä¼ æŒç»­æ—¶é—´',
  labelNames: ['status', 'file_size']
})

export const activeUploads = new client.Gauge({
  name: 'active_uploads',
  help: 'å½“å‰æ´»è·ƒçš„ä¸Šä¼ æ•°'
})

export const uploadErrors = new client.Counter({
  name: 'upload_errors_total',
  help: 'ä¸Šä¼ é”™è¯¯æ€»æ•°',
  labelNames: ['error_type']
})
```

---

## éƒ¨ç½²æ–¹æ¡ˆ

### Docker Compose é…ç½®

```yaml
# docker-compose.yml
version: '3.8'

services:
  # å‰ç«¯æœåŠ¡
  frontend:
    build: ./client
    ports:
      - "8080:80"
    depends_on:
      - backend

  # åç«¯æœåŠ¡
  backend:
    build: ./server
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - MONGODB_URI=mongodb://mongodb:27017/upload
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      - mongodb
      - redis
    volumes:
      - ./uploads:/app/uploads

  # MongoDB
  mongodb:
    image: mongo:7
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db

  # Redis
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  # Nginx
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend

volumes:
  mongodb_data:
  redis_data:
```

---

## æ€»ç»“

### å½“å‰å®ç° vs å¤§ä¸­å‹é¡¹ç›®

| ç‰¹æ€§ | å½“å‰å®ç° | å¤§ä¸­å‹é¡¹ç›® |
|------|----------|------------|
| **ä»£ç ç»„ç»‡** | å•æ–‡ä»¶ | æ¨¡å—åŒ–åˆ†å±‚ |
| **çŠ¶æ€ç®¡ç†** | Reactive | Pinia |
| **å¹¶å‘æ§åˆ¶** | ç®€å•é™æµ | Workeræ±  + ä»»åŠ¡é˜Ÿåˆ— |
| **å­˜å‚¨** | æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ | å¯¹è±¡å­˜å‚¨ï¼ˆS3/OSSï¼‰ |
| **ç¼“å­˜** | æ—  | Redis |
| **æ•°æ®åº“** | æ—  | MongoDB |
| **ç›‘æ§** | æ—  | Prometheus + Grafana |
| **æ—¥å¿—** | Console | Winston |
| **å®‰å…¨æ€§** | åŸºç¡€ | å®Œæ•´çš„è®¤è¯æˆæƒ |
| **éƒ¨ç½²** | æ‰‹åŠ¨ | Docker + K8s |

### è¿ç§»å»ºè®®

1. **æ¸è¿›å¼è¿ç§»**ï¼šå…ˆä¼˜åŒ–å‰ç«¯ï¼Œå†é‡æ„åç«¯
2. **ä¿æŒå…¼å®¹**ï¼šAPIæ¥å£ä¿æŒå‘åå…¼å®¹
3. **å……åˆ†æµ‹è¯•**ï¼šæ¯ä¸ªé˜¶æ®µéƒ½è¦è¿›è¡Œå®Œæ•´æµ‹è¯•
4. **ç›‘æ§å…ˆè¡Œ**ï¼šå…ˆå»ºç«‹ç›‘æ§ï¼Œå†è¿›è¡Œä¼˜åŒ–

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼š1.0  
**æœ€åæ›´æ–°**ï¼š2024-01-04  
**ä½œè€…**ï¼šDevFront
